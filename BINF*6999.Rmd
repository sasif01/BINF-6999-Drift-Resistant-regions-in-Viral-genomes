---
title: "Drift Resistant Regions in Viral Genomes"
author: "Saira Asif"
date: "`r Sys.Date()`"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(rentrez)
#install.packages("RFLPtools")
library(RFLPtools)
library(tidysq)
library(dplyr)
library(readr)
library(ape)
library(Biostrings)
#install.packages("MACER")
library(MACER)
library(stringi)
library(BiocManager)
library(DECIPHER)
```

## Introduction

Viral pathogens can change rapidly through a process called drift. Through this process, conserved regions of the genome accumulate mutation and substitutions. Antigenic drift refers to the lead to changes in the surface proteins, “antigens”, of the virus (Ryt-Hansen et al. 2020). Additionally, this drift-propensity can depend on the sequences within a region, the gene or the organisms involved. This propensity for drift makes diagnostics and vaccination a challenge. Additionally, there is the challenge of the detection these viral from different specimen. Given that the virus is consistently changing, the diagnostic tools are unable detect these viruses after significant drift. 


## Viral (Respiratory) genomes 

Viral genomes are obtained from NCBI and loaded into R using rentrez functions

```{bash}
# combine all individual fasta files (located in their own directories) into a single fasta file.
for i in GC*; do cat $i/* >> fastas; done
```

**Loading Data from NCBI**

```{r}
# vector of search terms for the ~26 genus of SubFamily Orthocoronavirinae
term= c("txid2569586[organism:exp] AND biomol_genomic[prop] NOT RefSeq","txid694015[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid300188[organism:exp] AND biomol_genomic[prop] AND 27000:28000[SLEN] NOT RefSeq", "txid1159908[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid572288[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid1159902[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid1159905[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid572289[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid1159907[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid1159904[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "txid1590370[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid290028[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid11138[organism:exp] AND biomol_genomic[prop] AND complete genome AND coronavirus NOT RefSeq", "Myodes coronavirus 2JL14 AND complete genome", "txid1541205[organism:exp] AND biomol_genomic[prop] NOT RefSeq", "Hedgehog coronavirus 1 AND complete genome NOT RefSeq", "txid1335626[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid694008[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "Tylonycteris bat coronavirus HKU4 AND complete genome NOT RefSeq", "txid1892416[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid694006[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "Severe acute respiratory syndrome-related coronavirus AND complete genome NOT RefSeq", "MT663548.1 NOT RefSeq", "Bat coronavirus CDPHE15 NOT RefSeq", "Alphacoronavirus CHB25 NOT RefSeq", "Alphacoronavirus WA3607 NOT RefSeq", "Bat coronavirus HKU10 AND complete genome NOT RefSeq", "Rhinolophus ferrumequinum alphacoronavirus HuB-2013 AND complete genome NOT RefSeq", "Human coronavirus 229E AND complete genome NOT RefSeq", "Lucheng Rn rat coronavirus AND complete genome NOT RefSeq", "Mink coronavirus 1 AND complete genome NOT RefSeq", "Miniopterus bat coronavirus 1 AND complete genome NOT RefSeq", "Miniopterus bat coronavirus HKU8 AND complete genome NOT RefSeq", "Myotis ricketti alphacoronavirus Sax-2011 AND complete genome NOT RefSeq", "Alphacoronavirus HKU33 AND complete genome NOT RefSeq", "Alphacoronavirus WA2028 AND complete genome NOT RefSeq", "Nyctalus velutinus alphacoronavirus SC-2013 AND complete genome NOT RefSeq", "Pipistrellus kuhlii coronavirus 3398 AND complete genome NOT RefSeq", "Alphacoronavirus WA1087 NOT RefSeq", "txid28295[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid693999[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid693998[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid277944[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "txid1920748[organism:exp] AND biomol_genomic[prop] AND complete genome NOT RefSeq", "Alphacoronavirus 1 AND complete genome NOT RefSeq" )


#empty vector to contain the ids for each sequence
ids <- c()
#retain at most 4 sequences from each search term. Obtain their ids.
for (i in term){
  search <- entrez_search("nucleotide", term=i, retmax=1)
  ids <- c(ids, search$ids)
}

length(ids)
#id_counts
as.vector(ids)

# fetching the seqeunces from NCBI as fasta files
covid_seqs <- entrez_fetch("nucleotide", id = ids, rettype = "fasta")

# fetching full genbank details to get taxonomy information
gen_file <- entrez_fetch("nucleotide", id = ids, rettype = "gb")

#writing to disk
write(covid_seqs, "covid_fastas", sep = "\n")
write(gen_file, "genback_file", sep = "\n")


```

**retrieving subgenera names from genbank detail**
```{bash}
# retrieving subgenera names from genbank detail
grep -A 3 "Virus" genback_file | grep -v -E "REF|AUTH|REMARK|JOURNA|\--|PUBMED|CONSRTM|TITLE|COMMENT|;$" | sed -E 's/ *//g' | grep -E "Alpha|Gamma|Beta|Delta|Nidovirales" | sed -E 's/.*;(.*);.*/\1/' | sed -E 's/^.*;//g'    

#Acesssion numbers from fasta file
grep ">" sequence.fasta | sed -E "s/>(.*\.[0-9]) +.*/\1/g"

#combine accnumber and subgenus names
paste -d "_" acc_list sub_list > new_names 
paste -d "_" acc_list subgenus  | sed 's/Gammacoronavirus/Brangacovirus/g' | sed -e 's/MT663548.1_Alphacoronavirus/MT663548.1_Amalacovirus/g' | sed 's/MK472070.1_Alphacoronavirus/MK472070.1_Decacovirus/g' | sed -e 's/MK472068.1_Alphacoronavirus/MK472068.1_Nyctacovirus/g' | sed -e 's/MK472067.1_Alphacoronavirus/MK472067.1_Pedacovirus/g' | sed -e 's/MK720944.1_AlphacoronavirusHKU33/MK720944.1_Nyctacovirus/g' | sed -e 's/MN611525.1_AlphacoronavirusCHB25/MN611525.1_Decacovirus/g' > new_names

#rename fasta file

#Fasta files into one liners to remove sequences 
sed -E 's/>/\n@>/g' news_fast | sed -E 's/(>.*)$/\1#/g' | tr -d "\n" | tr "@" "\n"
sed -E 's/$/#/g' cov_genus | sed -E 's/>/@>/g' | tr -d "\n" | sed -E 's/@/\n/g'

#extraxct sequences portion only
sed -E 's/$/#/g' sequence.fasta | sed -E 's/(>.*$)/\1@/g'  | tr -d '\n'| sed -E 's/>/\n/g' | sed -E 's/@/\n/g' | grep -v "genome" > seqs

#merge new names with sequnces
paste -d "@" new_names seqs | sed -E 's/[@|#]/\n/g'


```

VIRIDIC results

```{r}
#cov_clusters <- read_tsv("/Users/sairaasif49/Downloads/VIRIDIC_cluster_table.tsv")

#Distance matrix
cov_dist <- read_tsv("/Users/sairaasif49/Downloads/VIRIDIC_sim-dist_table.tsv") 

#Heat map from distance matrix
pivot_longer(cov_dist, cols=names(cov_dist)[-1], names_to = "genome2", values_to = "distance") %>%
  ggplot(aes(x=genome, y=genome2, fill=distance)) +
  geom_tile()

genus <- c("Gammacoronavirus", "Deltacoronavirus", "Betacoronavirus", "Alphacoronavirus")


cov <- cov_dist %>%
  separate(genome, sep="_(?=[^_]+$)", into=c("genome", "subgenus")) %>%
  select(genome, subgenus) %>%
  group_by(subgenus) %>%
  mutate(cn=n()) 

subgenus
sum(cov$subgenus =="Cegacovirus")

rep_c <- c()

for (i in subgenus) {
  if (i %in% names(table(cov$subgenus))){
    print("TURE")
    #rep_n= rep(i, table(cov$subgenus)[i])
    #rep_c = c(rep_c, rep_n)
    
  } else(
    print("F")
  )

}

names(table(cov$subgenus)) == "Brangacovirus"

length(unique(cov$subgenus))
length(rep_c)
rep(unique(cov$subgenus), as.vector(rep_c))


arrayInd(which.min(as.matrix(cov_dist[-1])), dim(as.matrix(cov_dist[-1])))
names(cov_dist[122,122])
cov_dist[122]

#Find idex of smallest value in matrix
cov_dist[which(cov_dist == min(cov_dist), arr.ind = TRUE)[1], which(cov_dist == min(cov_dist), arr.ind = TRUE)[2]]

cov_mat <- cov_dist[-1]
rownames(cov_mat) <- cov_dist$genome

#Finding smallest value 
which(cov_mat == min(cov_mat), arr.ind = TRUE)
cov_dist[39,1]
colnames(cov_mat[6])

min(apply(cov_dist[-1], 2, function(x){ min(x)}))


```


## Workflow for Isolating up-/down-stream regions of genes 

```{bash}
#Reformat the fasta file to have sequnces on one line 
sed -E 's/$/#/g' para_fastas | sed -E 's/(^>.*)#/\1@/g' | tr -d '\n'| sed -E 's/>/\n>/g' | sed -E 's/@/\n/g' | sed -E 's/#//g' > re_fasta

#Extract the start and end sites of genes from the gff3 file
#The file will have the acession codes (that are also in fasta file) and start/end sites for genes
grep -v '#' betaCov_lineageB.gff3 | cut -f1,4,5

#CDS lines to extract from gff3 files 
grep -v '#' betaCov_lineageB.gff3 | cut -f1,3,4,5,9 | grep -E 'CDS.*product' | cut -f1,2,3,4 > genes

#get product from the gff3 files for each CDS
grep -v '#' betaCov_lineageB.gff3 | cut -wcf1,3,4,5,9 | grep -E 'CDS.*product' | cut -f5 | sed -E 's/.*;(product=.*)/\1/g' | cut -d ';' -f1 > product

#combine the gens and product files
 paste -d '\t' genes product > genes
 
```

**Getting differances between start and end sites of adjacent genes**
```{r}
#reading in the genes_tsv file
genes <- read_tsv("genes_prod", col_names = F)
#Isolate the start-end columns

col1 <- genes[-1, 3]
col2 <- genes[-nrow(genes),4]

#Take differance between columns 
diff=col1-col2
#Add a arbritaty differance at the top of list (to ensure the vector is same length as the genes_tsv dataframe)
diff=rbind(150, diff)

#Write the diff file to wd
write_tsv(diff, 'gamma_diff', col_names = F)

```

```{bash}
#Combing the differance column with the genes_tsv columns
paste -d '\t' genes diff > genes_tsv
```

**Python script**
```{python}
import os
import re
import sys
from sys import argv

#genes=open("genes_tsv", 'r')
genes=open('primer_genes', 'r')
seqs=open('beta', 'r')
seqs_line=seqs.readlines()
cons=open('primer_cons', 'w')
seqs.close()

for i in genes.readlines():
        lines=i.rstrip()
        datalines=lines.split('\t')
        start_gene=int(datalines[2])
        end_gene=int(datalines[3])
        for index, line in enumerate(seqs_line):
                if (datalines[0] in line):
                        header=seqs_line[index]
#                       print(header)
                        head=header.rstrip()
                        nuc=seqs_line[index+1]
                        if ( start_gene==1 and end_gene<30):
                         print(head+''+datalines[1]+'\n'+nuc[start_gene:end_gene])
                        else:
                                print(head+''+datalines[1]+'\n'+nuc[start_gene:end_gene])

#for i in genes.readlines():
#       lines=i.rstrip()
#       datalines=lines.split('\t')
#       diff=int(datalines[4])
#       if (diff > 20 and diff < 200):
#               start_gene=int(datalines[1])
#               int_list1up=start_gene-diff
#               end_gene=int(datalines[2])
#               int_list2down=end_gene+diff
#               for index, line in enumerate(seqs_line):
#               #       seq_line=line.rstrip()
#                       if (datalines[0] in line):
#                               header=seqs_line[index]
#                               head=header.rstrip()
#                               nuc=seqs_line[index+1]
##                              print(head+' '+datalines[3]+'\n'+nuc[int_list1up:start_g$
                        #       cons.write(head+' '+datalines[3]+'\n'+nuc[int_list1up:st$

```

**Alignments using muscle - grouped based on genes**

```{r}
seqs <-read_fasta("gamma_cons")
seqs <- read_fasta('M_cons')
seqs$prods <- str_replace(seqs$name, '.*product=', '') 

seqs$prods <- str_replace(seqs$prods, '.*protein M', 'membrane protein M')
seqs$prods <- str_replace(seqs$prods, '^M$', 'membrane protein M')
seqs$prods <- str_replace(seqs$prods, 'M protein', 'membrane protein M')
seqs$prods <- str_replace(seqs$prods, 'Orf14', 'ORF14')
seqs$prods <- str_replace(seqs$prods, 'ORF 8', 'ORF8')

seqs$prods <- str_replace(seqs$prods, 'ORF8 .*', 'ORF8')
seqs$prods <- str_replace(seqs$prods, 'orf8.*', 'ORF8')
seqs$prods <- str_replace(seqs$prods, 'orf10.*', 'ORF10')
seqs$prods <- str_replace(seqs$prods, 'ORF10.*', 'ORF10')
seqs$prods <- str_replace(seqs$prods, 'hypothetical.*ORF10', 'hypothetical ORF10')
seqs$prods <- str_replace(seqs$prods, 'hypothetical.*orf14.*', 'hypothetical ORF14')
unique(seqs$prods)

df=as.data.frame(seqs)
seqs$sq2 <- DNAStringSet(df$sq)

aligns <- c()
consensusseq <- c()
for (i in unique(seqs$prods)){
  sti <- seqs %>%
    filter(prods==i) 
  sti <- as.data.frame(sti)
  if (nrow(sti) >2){
   sti$seq2 <-  DNAStringSet(sti$sq) 
  names(sti$seq2) <- sti$prods
  alignment <- DNAStringSet(muscle::muscle(sti$seq2, gapopen=-5, gapextend=2), use.names=T)
  cons <- ConsensusSequence(alignment)
  aligns <- c(aligns, alignment) 
  consensusseq <- c(consensusseq, cons)
  }
}

str_
consensusseq[[4]]
BrowseSeqs(aligns[[6]])
length(aligns[[6]])
str_count(as.data.frame(ConsensusSequence(aligns[[6]])), '\\+')/width(ConsensusSequence(aligns[[6]]))
ConsensusSequence(aligns[[6]])

alpha <- readDNAStringSet("Sars/2020-7_2020-12")
alpha2 <- readDNAStringSet("Sars/2020-9_2021-2")
alignment <- DNAStringSet(muscle::muscle(alpha2, gapopen=-5, gapextend=2), use.names=T)
ConsensusSequence(alignment)
BrowseSeqs(alignment)
```


## Changing header to include subgenus names on fasta file
```{r}

#Adding Subgenus names to FASTA headers
names_file <- read_lines("/Users/sairaasif49/Desktop/BINF*6999/na")
names_file <- names_file %>%
   str_remove(">")

#read in fasta file as df with sq column and 
fast <- read_fasta("/Users/sairaasif49/Desktop/BINF*6999/sequence.fasta") 

str_locate_all(fast$sq, "!")
str_count(fas$sq, "!")

names2 <- fas$name %>%
  str_remove("^[A-z0-9.]+") 

new_names <- paste(names_file, names2, sep="")  
 
write_fasta(fas$sq, new_names, "new_names_fasta")

new_fas <- read_fasta("/Users/sairaasif49/Desktop/BINF*6999/new_names_fasta") 


```

## Viral Classification 
```{r}
cov_genus <- read_tsv("/Users/sairaasif49/Desktop/BINF*6999/covid_tsv",col_names = F) 
colnames(cov_genus) <- c("seq", "genus", "subgenus")
#cov_genus$seq2 <- DNAStringSet(cov_genus$seq)
#names(cov_genus$seq2) <- cov_genus$subgenus
#alignment <- DNAStringSet(muscle::muscle(cov_genus$seq2, maxiters=2), use.names=T)
#writing aligned file to disk
#writeXStringSet(alignment, "cov_align")


# Aligning sequences genus-wise
aligns <- c()
for (i in unique(cov_genus$genus)){
  sti <- cov_genus %>%
    filter(genus==i) 
  sti <- as.data.frame(sti)
  #print(sti)
  sti$seq2 <-  DNAStringSet(sti$seq)
  #print(sti)
  names(sti$seq2) <- sti$subgenus
   #alignment <- DNAStringSet(muscle::muscle(sti$seq2, maxiters=2, gapopen=-1000), use.names=T)
   alignment <- DNAStringSet(muscle::muscle(sti$seq2, gapopen=-5, gapextend=2), use.names=T)
   aligns <- c(aligns, alignment)
}
#started 1:25
BrowseSeqs(aligns[[1]])
aligns[[1]][1:3]
write(aligns[[1]], "gamma", sep = "\\s")

# Wirting alingments of disk
writeXStringSet(c(aligns[[1]], aligns[[2]],aligns[[3]],aligns[[4]]), "cov_align")
writeXStringSet(aligns[[1]], "gamma_align")
writeXStringSet(aligns[[2]], "delta_align")
writeXStringSet(aligns[[3]], "beta_align")
writeXStringSet(aligns[[4]], "alpha_align")

# Clustering and Dendogram of alignment
for (i in aligns) {
  bin <- as.DNAbin(i)
  dist_mat <- dist.dna(bin, model = "JC69", as.matrix=T )
  dist_mat <- as.dist(dist_mat)
  clust <- hclust(dist_mat, method = "single")
  plot(clust)
}


```


#Paramyxoviridae
```{r}

terms =c ("(Metaavulavirus AND complete genome) AND "Avian metaavulavirus 6"[porgn:__txid2560316]", "(Metaavulavirus AND complete genome) AND "Avian metaavulavirus 2"[porgn:__txid2560313]", "(Metaavulavirus AND complete genome) AND "Avian metaavulavirus 8"[porgn:__txid2560318]", "(Metaavulavirus AND complete genome) AND "Metaavulavirus falklandense"[porgn:__txid2560309]", "(Metaavulavirus AND complete genome) NOT (Avian metaavulavirus 6 OR Avian metaavulavirus 8 OR Avian metaavulavirus 2 OR Metaavulavirus falklandense)", "((Orthoavulavirus AND complete genome)) AND "Avian orthoavulavirus 1"[porgn:__txid2560319]", "((Orthoavulavirus AND complete genome)) AND "Pigeon paramyxovirus 1"[porgn:__txid159079]", "((Orthoavulavirus AND complete genome)) NOT ("Pigeon paramyxovirus 1"[porgn:__txid159079] OR Avian orthoavulavirus 1)", "((Paraavulavirus AND complete genome)) AND "Avian paraavulavirus 4"[porgn:__txid2560328]", "((Paraavulavirus AND complete genome)) AND "Avian paraavulavirus 3"[porgn:__txid2560327]", "(Aquaparamyxovirus AND complete genome)", "(Ferlavirus AND complete genome)", "(Henipavirus AND complete genome)", "")



terms=c("Metaavulavirus AND complete genome) AND Avian metaavulavirus 6", "(Metaavulavirus AND complete genome) AND Avian metaavulavirus 2", "(Metaavulavirus AND complete genome) AND Avian metaavulavirus 8", "(Metaavulavirus AND complete genome) AND Metaavulavirus falklandense", "(Aquaparamyxovirus AND complete genome)", "(Ferlavirus AND complete genome)", "(Henipavirus AND complete genome)", "(Jeilongvirus AND complete genome)", "(Morbillivirus AND complete genome)", "(Narmovirus AND complete genome)", "(Respirovirus AND complete genome)", "(Salemvirus AND complete genome)", "(Rubulavirinae AND Orthorubulavirus AND complete genome )", "(Rubulavirinae AND Pararubulavirus AND complete genome )","Cynoglossusvirus", "Hoplichthysvirus", "Scoliodonvirus", "Metaparamyxovirinae")


ids <- c()
#retain at most 4 sequences from each search term. Obtain their ids.
for (i in terms){
  search <- entrez_search("nucleotide", term=i, retmax=5)
  ids <- c(ids, search$ids)
}
length(ids)

#Make sequenes and headers into a single line


# fetching the seqeunces from NCBI as fasta files
para_seqs <- entrez_fetch("nucleotide", id = ids, rettype = "fasta")

# fetching full genbank details to get taxonomy information
paragen_file <- entrez_fetch("nucleotide", id = ids, rettype = "gb")

#writing to disk
write(para_seqs, "para_fastas", sep = "\n")
write(paragen_file, "paragenback_file", sep = "\n")


 grep -A 3 "Virus" paragenback_file | grep -v -E "REF|AUTH|REMARK|JOURNA|\--|PUBMED|CONSRTM|TITLE|COMMENT|;$" | sed -E 's/ *//g' | cut -d ';' -f1 | grep -v '\.' | grep -v -E 'Antib' | grep -v 'RespiratoryTractInfectioninExperimentallyChallengedFerrets' > subs
 
 
 grep -A 3 "Virus" paragenback_file | grep -v -E "REF|AUTH|REMARK|JOURNA|\--|PUBMED|CONSRTM|TITLE|COMMENT|;$" | sed -E 's/ *//g' | cut -d ';' -f1,2 | grep -v -E 'salmonis|Respiratory|Antibodies' | sed -E 's/;/ (SubFamily)_/g' |  grep -A 3 "Virus" paragenback_file | grep -v -E "REF|AUTH|REMARK|JOURNA|\--|PUBMED|CONSRTM|TITLE|COMMENT|;$" | sed -E 's/ *//g' | cut -d ';' -f1,2 | grep -v -E 'salmonis|Respiratory|Antibodies' | sed -E 's/;/(SubFamily)_/g' | sed -E 's/(Cynoglossusvirus|Hoplichthysvirus|Scoliodonvirus)\(SubFamily)/\1(Genus)/g' | sed -E 's/$/(Genus)/g' > subs
 
 
 grep ">" para_fastas | sed -E "s/(>.*\.[0-9]) +.*/\1/g" > acc_numbers
 
 paste -d "_" acc_numbers subs > new_names
 
 #extraxct sequences portion only
 sed -E 's/$/#/g' para_fastas | sed -E 's/(^>.*)#/\1@/g' | tr -d '\n'| sed -E 's/>/\n>/g' | sed -E 's/@/\n/g' | grep -v ">" > seqs
 
 #merge new names with sequnces
paste -d "@" new_names seqs | sed -E 's/[@|#]/\n/g'


sed -E 's/$/#/g' para_new_fasta | sed -E 's/(^>.*)#/\1@/g' | tr -d '\n'| sed -E 's/>/\n>/g' | grep 'Avulavirinae'  | sed -E 's/@/\n/g' | sed -E 's/[@|#]/\n/g' > Avulavirinae_subfamily_fasta



```

```{r}
sars <- readDNAStringSet("Sars/sequences_20230621_3319914.fasta")
alignment <- DNAStringSet(muscle::muscle(sars, gapopen=-5, gapextend=2), use.names=T)

```

**Timeframes SARS-Cov-2**

```{bash}
#Aligning the sequences in muscle in computecanada
for i in sequences_20230621_*; do sbatch align_script $i; done

#Remote to local
scp -r sasif01@graham.computecanada.ca:scratch/BINF_6999/sequences_20230621_393424.align  .
```

```{r}
library(fs)
#Get file path for each file
file_path <-dir_ls(path='./Sars', regexp = '[0-9]$')

#Empty list that will hold the aligned files
file_content=list()
file_content=c()
?ConsensusSequence
#Loop to open each aligned file and return consensus sequence.
for(i in seq_along(file_path)){
  file_content[i] <- as.data.frame(ConsensusSequence(readDNAStringSet(file_path[[i]])))$x
}

file_content <- set_names(file_content, word(file_path, 3L, sep = '/'))

write(file_content, 'test')
write(names(file_content), 'name')

```

##OBJECTIVE##

Molecular diagnostic assays require unique and conserved genomic regions to rapidly identify viruses. However, high mutation rates and genetic drift can result in a loss of sensitivity over time. Identifying stable, drift-resistant regions in viral genomes could be used to better molecular assays techniques. The aim of this project is to outline a bioinformatic pipeline that can identify drift-resistant regions of viral genomes. The analysis focuses on respiratory viruses (Influenza, SARS-Cov-2 etc.) with the potential of extending to other human pathogenic viruses. Identification of drift-resistant regions will allow us to complement the standard alignment-based process for viruses with extensive number of sequence submissions. The need to rapidly identify these variants is essential to the developments of vaccinations and public health measures/prevention plans. The development of this pipeline would enable us to identify features of the drift-resistant regions that can be targeted to improve detection of viruses undergoing drift. This would significantly reduce diagnostic detection time and ensure a rapid response to the presence of pathogen in specimens. 

##METHODS##

####TIMEFRAMES#####

###DATA 

Aligned sequences are retrieved from Nextstrain (aligned.fasta). The sequences were aligned using Nextclade with MN908947 (Wuhan-Hu-1) as a reference.

Downloading data from NCBI Virus. 
Up to 2000 sequences were retrieved for each varient, along with a results table (metadata) containing Accession, Release Date, Panoglin, Length, Country, Collection Date. An addition column is added to each table to include the WHO lineage for each varient. 

Instructions for adding a Lineage column to data

```{bash}
#Create a single File with the name of the Lineage. 

echo 'Lineage' > Lineage
# first variant should keep the headers information
sed rLineage var1.meta | sed 'N;s/\n/,/' > var1.meta
#Change first 'Lineage' (in header) to Lineage
sed -E 's/(.*,Collection_Date,)Delta/\1Lineage/g'

#remove header info from second and all remaining variants 
sed rLineage var1.meta | sed 'N;s/\n/, /' | grep -v 'Pangolin' >  var2.meta

#Loop for it for all files at once
for i in *.meta; do sed rLineage $i | sed 'N;s/\n/, /' > $i.meta; done

#Concatenate all the varients into a single file (do the same for sequence data)
cat var1.meta var2.mets var3.meta > Lineage.meta

#Custom buil selection: Accession,Panolin, length, Country , Collection Date, Release Date, Genbank Title

#building meta file
 grep '>' sequences.fasta | cut -d ' ' -f1,2 | sed -E 's/\|/,/g' | sed -E 's/,Se.*//g' | sed -E 's/>//g' > varient.meta
 
 cat alpha.fasta beta.fasta epsilon.fasta eta.fasta iota.fasta mu.fasta tu.fasta zeta.fasta > lineages.fasta
 
```


Separating into Timeframes

Custom python script is used to organize sequences into time time-intervals with varying degree of overlap.

```{python}
import re
import sys
from sys import argv
from itertools import count

####TIMEFRAMES (As a function)#####

#4 months (2month overlap) = overlap: range(0,12,2) and window : range(1,5)
#6 month (2 month overlap) = overlap: range(0,12,2) and window : range(1,7)
def timeframes(window, overlap):
        file1=open(sys.argv[1], 'r') #FIRST COMMAND  LINE ARGUMENT: metadata file
        seqs=open(sys.argv[2], 'r') # SECOND COMMAND LINE ARGUMENT : fasta file 
        seq_lines=seqs.readlines()
        file1_line=file1.readlines()
        dict={}
        for i in file1_line:
            lines=i.rstrip()
            datalines=lines.split(',') #Specify the delimiter from the metadata file 
            for j in range(18,23):
                for k in range(0,12,overlap): #Adjust this to alter overalp (2-/4-months etc.)
                    for l in range(1,window+1): #Adjust this to alter time intervals (4-/ 6-months etc.)
                        if (k+window <=12):
                            for m in re.findall('20'+str(j)+r'-'+"{:02d}".format(k+l), lines):
                                if ('20'+str(j)+'-'+str(k+1)+'_20'+str(j)+'-'+str(k+window) not in dict.keys()):
                                    dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j)+'-'+str(k+window)]=[]
                                dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j)+'-'+str(k+window)].append(datalines[0])
                        else:
                            for m in re.findall('20'+str(j+1)+'-'+"{:02d}".format(k+l-12),lines):
                                if ('20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12) not in dict.keys()):
                                    dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12)]=[]
                                dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12)].append(datalines[0])
                            for n in re.findall('20'+str(j)+'-'+"{:02d}".format(k+l),lines):
                                if ('20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12) not in dict.keys()):
                                    dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12)]=[]   
                                dict['20'+str(j)+'-'+str(k+1)+'_20'+str(j+1)+'-'+str(k+window-12)].append(datalines[0])
  for i in d.keys():
                fasts=open(i,'w')
                for index, line in enumerate(seq_lines):
                        for j in d[i]:                  
                                if (j in line):
                                        header=seq_lines[index]
                                        head=header.rstrip()
                                        nuc=seq_lines[index+1]
                                        fasts.write(header.rstrip()+'\n'+nuc)
                                        
  #Ensures no duplicate values/accession code across keys                                  
  d={key:value for key, value in zip(dict.keys(), [list(set(dict[i])) for i in dict.keys()])}
  
  #Extract the sequences for each timeframe (key in the dict), whose accession numbers are in the list of value for each key
  for i in d.keys():
    fasts=open(i,'w')
    for index, line in enumerate(seq_lines):
      for j in d[i]:
        if (j in line):
          header=seq_lines[index]
          nuc=seq_lines[index+1]
          fasts.write(header.rstrip()+'\n'+nuc)
      
```

4-month (2 month overlap)

**Alignments**

```{bash}
#Align all fasta files for each variant 
for i in *; do mafft $i > $i.aligned; done
```


Total of 20 fasta files generated after separating into time intervals

```{r}
library(fs)
#Get file path for each file
file_path <-dir_ls(path='./Sars/LINEAGES/ALIGNED_FILES', regexp = 'aligned$')

#Empty list that will hold the aligned files
file_content=c()

for(i in seq_along(file_path)){
  file_content[i] <- as.data.frame(ConsensusSequence(readDNAStringSet(file_path[[i]])))$x
}

#Reading in variant information for 4-month intervals 
vars <- read_tsv("Sars/NEXTSTRAIN/6_months/varients_6", col_names = F )
names(vars) <- c("date", "varients")
vars$varients <- str_replace(vars$varients, '[0-9]+[A-z] ', '')
vars$varients <- str_replace(vars$varients, ',.*', ')')

#Histogram of number of sequences at each interval split by varient type
# Majority of sequences are Omicron after 2022
vars %>%
  ggplot() + geom_histogram(aes(date, fill=varients), stat = "count") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))

ls
#Setting name of each consensus as the time range
file_content <- set_names(file_content, word(file_path, 5L, sep = '/'))

#Write the consensus seq and names as two different files
#write(file_content, 'seqs')
#write(names(file_content), 'headers')

#Writing all consensus seqs for each time range to a single file 
write(paste(names(file_content), file_content, sep = '\n'), 'Consensus_4mnVars')

```

6-month (2 month overlap)


```{r}
#Reading in varient information for 4-month intervals 
vars <- read_tsv("Sars/NEXTSTRAIN/varients_6", col_names = F )
names(vars) <- c("date", "varients")
vars$varients <- str_replace(vars$varients, '[0-9]+[A-z] ', '')
vars$varients <- str_replace(vars$varients, ',.*', ')')

unique(vars$date)
vars %>%
  ggplot() + geom_histogram(aes(date, fill=varients), stat = "count") + theme(axis.text.x = element_text(angle = 90, vjust = 0.5, hjust=1))
```

Scoring the Consensus Sequences

A custom python script is used to fragment the consensus sequences and 'score' each segment, while filtering out low scoring regions.
The remaining fragments will be considered highly conserved. 

Additionally, only fragments that appear across all time-ranges (in each consensus seq) are kept for further comparisons 

```{python}

import re
import os
import sys
from os import path
from sys import argv

seq=open(sys.argv[1], 'r')
seq_lines=seq.readlines()

#FIRST COMMAND LINE ARGUMENT: the file of consesuss sequences for each timframe (in one file)
con=open(sys.argv[2], 'r')
con_lines=con.readlines()

#conservation scores for each consesusus sequnces for each timframe file 
#for file in os.listdir(r'/Users/sairaasif49/Desktop/BINF*6999/Sars/frames/'):
#       #zuc holds the aligned seqices from each timeframe 
#       zuc=[]
#       files=open(file, 'r')
#       files_lines=files.readlines()
#       for index, line in enumerate(files_lines):
#               if (line.startswith('>')):
#                       zuc.append(files_lines[index+1])
#
#       stretch=open(file+'_stretches', 'w')
#       #counts how many time the aligned sequnces have the same character as the consesus seq  
#       for index2, line2 in enumerate(con_lines):
#               if (line2.startswith(file)):
#                       header2=con_lines[index2]
#                       con_seq=con_lines[index2+1]
#                       d=[i[1].count(i[0]) for i in zip(con_seq, zip(*zuc))]
#                       b=[len(i[1]) for i in zip(con_seq, zip(*zuc))]
#                       #Scores each nucleotide site for each consensus sequence
#                       s=[d[i]/b[i] for i in range(0,len(d))]
#                       #Scores the whole consensus seq (one number)
#               #       s=sum([d[i]/b[i] for i in range(0,len(d))])/len(con_seq)
#                       idx_list = [idx + 1 for idx, val in enumerate(s) if val <= 0.95]
#                       res = [s[i: j] for i, j in zip([0] + idx_list, idx_list +([len(s)] if idx_list[-1] != len(s) else []))]                       
#                       lis=[[i, len(val)] for i,val in enumerate(res) if len(val) > 100]
#                       seq=[[j[0],j[0]+j[1],con_seq[j[1]:j[0]+j[1]]] for j in lis]
#                       fil='\n'.join(','.join([str(elem) for elem in x]) for x in seq)
#                       fil2=re.sub('(,[^,]*),', r'\1\n', fil).replace(',', '-')
#                       fil3=re.sub(r'([0-9]+-[0-9]+)', r'>\1', fil2)
#                       stretch.write(fil3)
```


**COMPLICATED: Lineages approach**

Delta : 2 major variants (Delta Plus:AY.4.2, Delta:B.1.617.2)

Filters
Delta Plus (53) - Location : USA, Host : Homo Sapiens, Nucleotide Completeness : complete.
Delta (7710) -  Location : USA, Host : Homo Sapiens, Nucleotide Completeness : complete, Ambiguous Characters: 0

```{bash}
#Align all fasta files for each variant 
for i in *; do mafft $i > $i.aligned; done
```

Consensus sequences file

```{r}
library(fs)
#Get file path for each file
file_path <-dir_ls(path='./Sars/DELTA_VARIENT', regexp = 'aligned$')

#Empty list that will hold the aligned files
#file_content=list()
file_content=c()

#Loop to open each aligned file and return consensus sequence.
for(i in seq_along(file_path)){
  file_content[i] <- as.data.frame(ConsensusSequence(readDNAStringSet(file_path[[i]])))$x
}

file_content <- set_names(file_content, word(file_path, 4L, sep = '/'))

write(file_content, 'test')
write(names(file_content), 'name')

```

```{bash}
#Final consensus seq file
paste -d '\n' name test > delta_consensus
```

Epsilon : 2 varients 
```{r}
#Get file path for each file
file_path <-dir_ls(path='./Sars/EPSILON_VARIENT', regexp = 'aligned$')

#Empty list that will hold the aligned files
#file_content=list()
file_content=c()

#Loop to open each aligned file and return consensus sequence.
for(i in seq_along(file_path)){
  file_content[i] <- as.data.frame(ConsensusSequence(readDNAStringSet(file_path[[i]])))$x
}

file_content <- set_names(file_content, word(file_path, 4L, sep = '/'))

write(file_content, 'epsilon')
write(names(file_content),'header')

```

Single Variant - split into timeframes - get metadata information  
Alpha : 1 major variant B.1.1.7











